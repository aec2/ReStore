Great—there are some clear hotspots here. Below is a focused plan with concrete code changes to cut DB round-trips, cache SAP lookups, validate in bulk, and commit fewer, larger writes. I’ll show a drop-in rewrite of your method and the helpers it depends on.


---

Key bottlenecks (and the fixes)

1. N+1 repository calls in validators

IsBatchInTezgah/IsBatchInToolcrib call GetAll().FirstOrDefault(...) for each item.
✅ Fix: Load all needed batches once into a dictionary and validate from memory.



2. Repeated SAP calls

_sapService.GetMaterial(toolNumber) is called multiple times per item.
✅ Fix: Batch-load or at least cache materials by toolNumber for this request (IMemoryCache or per-request dictionary). You already batch stocks with GetAllStock(materialNumbers)—do the same for materials if possible.



3. Repeated lookups for GoodsGroup → CostCenter

_goodsGroupService.GetByGroupName is called per item.
✅ Fix: Preload distinct group names once and memoize CostCenter.



4. Row-by-row updates

CloseAllRequestByBatchNumber loads entities then updates one by one.
✅ Fix: Resolve the target StatusId once, then issue a single bulk update (raw SQL in EF Core 3.1, or EFCore.BulkExtensions if allowed).



5. Multiple SaveChanges / Unit of Work scope

Scattered updates (_batchService.Update, repository Inserts/Updates) cause multiple transactions.
✅ Fix: Wrap everything in a single ABP IUnitOfWork and call SaveChanges() once.



6. Tracking & mapping overhead

Use .AsNoTracking() for reads; avoid mapping back and forth if not needed.



7. Do local validations before external calls

Fail fast to avoid expensive SAP calls when inputs are invalid.



8. Indexes

Ensure DB indexes on Batch.BatchNumber, OperatorRequest.Id (already PK), and any foreign keys used by filters. (One-time schema action.)





---

Refactored code (request-scoped caching + set-based access + single UoW)

> Notes:

If you don’t have SAP batch endpoints, keep the in-memory cache approach.

For brevity, I show synchronous signatures like yours; if you can, switch to async everywhere.




// Add a lightweight request-scoped cache (can be field on the AppService)
private readonly Dictionary<string, Material> _materialCache = new(StringComparer.OrdinalIgnoreCase);
private readonly Dictionary<string, string> _goodsGroupToCostCenter = new(StringComparer.OrdinalIgnoreCase);

public List<GrindingResultDto> CreateByList(List<GrindingDto> grindingDtoList)
{
    using (var uow = _unitOfWorkManager.Begin(new AbpUnitOfWorkOptions
    {
        // Avoid multiple SaveChanges; one commit at the end
        IsTransactional = true
    }))
    {
        var results = new List<GrindingResultDto>(grindingDtoList.Count);

        // 1) Preload essentials

        // Distinct keys
        var batchNumbers = grindingDtoList.Select(x => x.BatchNumber).Where(x => !string.IsNullOrWhiteSpace(x)).Distinct().ToList();
        var toolNumbers  = grindingDtoList.Select(x => x.ToolNumber).Where(x => !string.IsNullOrWhiteSpace(x)).Distinct().ToList();

        // Batches in one go (no tracking)
        var batches = _batchRepository
            .GetAll()
            .AsNoTracking()
            .Where(b => batchNumbers.Contains(b.BatchNumber))
            .ToList()
            .ToDictionary(b => b.BatchNumber, b => b, StringComparer.OrdinalIgnoreCase);

        // Stocks already batched
        var stocks = _sapService.GetAllStock(toolNumbers);

        // Materials: try batch endpoint; fallback to per-item with memoization
        var materials = TryGetMaterialsBatch(toolNumbers) 
                        ?? toolNumbers.ToDictionary(t => t, t => GetMaterialMemoized(t), StringComparer.OrdinalIgnoreCase);

        // GoodsGroup → CostCenter (preload distinct)
        var goodsGroups = materials.Values
                                   .Select(m => m?.GoodsGroup)
                                   .Where(g => !string.IsNullOrWhiteSpace(g))
                                   .Distinct(StringComparer.OrdinalIgnoreCase)
                                   .ToList();

        foreach (var gg in goodsGroups)
        {
            if (!_goodsGroupToCostCenter.ContainsKey(gg))
            {
                var dto = _goodsGroupService.GetByGroupName(gg); // single call per group
                _goodsGroupToCostCenter[gg] = dto.CostCenter;
            }
        }

        // Resolve frequently used values once
        var closedStatusId = _statusService.GetStatusByStatusCode(RequestStatus.KAPALI).Id;

        // 2) Validate all inputs from memory before any write / SAP movement
        ValidateBatchesNotInStores(batches, batchNumbers);

        // 3) Process items
        foreach (var grindingDto in grindingDtoList)
        {
            var result = new GrindingResultDto
            {
                BatchNumber = grindingDto.BatchNumber,
                ToolNumber  = grindingDto.ToolNumber,
                IsSuccess   = false,
                ErrorMessage = ""
            };

            try
            {
                // Get batch snapshot (no tracking) for validations & calculations
                if (!batches.TryGetValue(grindingDto.BatchNumber, out var batchEntity))
                    throw new UserFriendlyException(404, $"Batch '{grindingDto.BatchNumber}' not found.");

                // Pure validations (no DB calls)
                _grindingDomainService.IsGrindingAndScrapAmountAvailableForSave(grindingDto.GrindingAmount, grindingDto.ScrapAmount);
                _grindingDomainService.CompareGrindingAmountAndBatchAmount(grindingDto.GrindingAmount, batchEntity.Amount);
                _grindingDomainService.CompareScrapAmountAndBatchAmount(grindingDto.ScrapAmount, batchEntity.Amount);

                if (grindingDto.Batch.GrindingLife == 0)
                    throw new UserFriendlyException(502, "The batch's grinding life should be more than zero");

                // Lookup material + cost center from cache
                var material    = materials[grindingDto.ToolNumber];
                var costCenter  = material?.GoodsGroup is string gg && _goodsGroupToCostCenter.TryGetValue(gg, out var cc) ? cc : null;

                // Precomputed storage amount from preloaded stocks
                var storageAmount = stocks.Where(x => x.MaterialNumber == grindingDto.ToolNumber
                                                      && x.StorageLocation == StorageLocation.YariMamul
                                                      && x.ProductionLocation == ProductionLocation.Imalat)
                                          .Sum(x => x.TahditsizStock);

                // Compute decline
                decimal declineAmount = 0m;
                var grinding = ObjectMapper.Map<Grinding>(grindingDto);
                if (grindingDto.GrindingAmount != 0)
                    declineAmount = _grindingDomainService.GetGrindingDeclineAmount(grinding, grindingDto.Batch.GrindingLife);

                if (grindingDto.ScrapAmount != 0)
                    declineAmount = _grindingDomainService.GetScrapDeclineAmount(grinding, grindingDto.ScrapAmount, declineAmount);

                declineAmount = Math.Round(Math.Max(0, declineAmount), 3);

                // Close related operator requests in one shot (bulk)
                CloseAllRequests_Bulk(grindingDto.BatchNumber, closedStatusId);

                // Update batch (load tracked entity once)
                var batchDb = _batchRepository.Get(grindingDto.Batch.Id); // tracked
                batchDb.AmountLeft = (batchDb.AmountLeft ?? 0) - declineAmount;
                batchDb.Store      = BatchStore.Bilenmis_Atolye;

                _batchRepository.Update(batchDb);

                // Insert grinding record (minimal fields)
                _grindingRepository.Insert(new Grinding
                {
                    BatchId       = grindingDto.BatchId,
                    GrindingAmount= declineAmount,
                    GrindingTimes = grindingDto.GrindingTimes,
                    ScrapAmount   = grindingDto.ScrapAmount
                });

                // SAP movement only if we have stock and a positive decline
                if (declineAmount > 0 && storageAmount >= declineAmount)
                {
                    var now = Clock.Now;
                    var goodsMovement = new GoodsMovement
                    {
                        DocumentDate = now,
                        MoveType     = SapMoveType.DepodanMasrafYeriIcinTuketim,
                        PartNo       = grindingDto.ToolNumber,
                        Quantity     = declineAmount,
                        Batch        = material?.IsBatch == true ? "X" : "",
                        GmCode       = "03",
                        FromStorage  = StorageLocation.YariMamul,
                        CostCenter   = costCenter,
                        FromPlant    = ProductionLocation.Imalat
                    };
                    _sapService.DoGoodsMovement(goodsMovement);
                }

                // Deactivate batch if scrap consumes all
                if (grindingDto.ScrapAmount != 0)
                {
                    var totalScrap = (grindingDto.Batch.ScrapTimes) + grindingDto.ScrapAmount;
                    if (grindingDto.Batch.Amount <= totalScrap)
                    {
                        batchDb.Status = false;
                        _batchRepository.Update(batchDb);
                    }
                }

                result.IsSuccess = true;
            }
            catch (Exception ex)
            {
                result.ErrorMessage = ex.Message;
            }

            results.Add(result);
        }

        // 4) Commit once
        uow.Complete();

        return results;
    }
}

// ---------- Helpers ----------

// Try batch materials; else null
private Dictionary<string, Material> TryGetMaterialsBatch(List<string> toolNumbers)
{
    // If your SAP service exposes a batch endpoint, implement & use it here:
    // return _sapService.GetMaterials(toolNumbers).ToDictionary(m => m.Number, m => m);
    return null;
}

private Material GetMaterialMemoized(string toolNumber)
{
    if (_materialCache.TryGetValue(toolNumber, out var m)) return m;
    m = _sapService.GetMaterial(toolNumber);
    _materialCache[toolNumber] = m;
    return m;
}

private void ValidateBatchesNotInStores(Dictionary<string, Batch> batches, IEnumerable<string> batchNumbers)
{
    foreach (var bn in batchNumbers)
    {
        if (!batches.TryGetValue(bn, out var b)) continue;
        if (b.Store == BatchStore.Tezgah)
            throw new UserFriendlyException(502, $"{bn} numaralı batch tezgahta bulunmaktadır. Bileme kaydı yapılamaz.");
        if (b.Store == BatchStore.Toolcrib)
            throw new UserFriendlyException(502, $"{bn} batch is in Toolcrib.");
    }
}

// Single bulk close instead of per-row updates
private void CloseAllRequests_Bulk(string batchNumber, int closedStatusId)
{
    // Resolve related request ids once
    var operatorRequestIds = _batchDetailService.GetAllByBatchNumber(batchNumber)
                                .Select(x => x.OperatorRequestId)
                                .Distinct()
                                .ToList();
    if (operatorRequestIds.Count == 0) return;

    // EF Core 3.1 doesn’t have ExecuteUpdate; use raw SQL for bulk update
    // (Adjust table/column names and schema as needed)
    var ctx = _operatorRequestRepository.GetDbContext();
    var idsCsv = string.Join(",", operatorRequestIds);

    // To avoid SQL injection, use table-valued parameters or temp table in production.
    // For brevity, parameterize in chunks:
    var parameters = operatorRequestIds.Select((id, i) => new SqlParameter($"@p{i}", id)).ToArray();
    var inClause  = string.Join(",", parameters.Select(p => p.ParameterName));

    ctx.Database.ExecuteSqlRaw(
        $"UPDATE OperatorRequests SET StatusId = @statusId WHERE Id IN ({inClause})",
        new[] { new SqlParameter("@statusId", closedStatusId) }.Concat(parameters).ToArray()
    );
}


---

Additional quick wins

Mark read-only queries with .AsNoTracking() (you already do in one place—apply consistently).

Chunk very large grindingDtoList (e.g., process in blocks of 200–500 to keep memory & transaction size reasonable).

Add DB indexes

IX_Batch_BatchNumber

If you filter by ToolNumber frequently, index that too.


Move costly checks to be pure
Ensure domain service checks don’t hit the DB. If they must, pass the already-loaded data.

Consider async
If your SAP client is async and your repos can be async, switch to async/await end-to-end to free threads.

HTTP timeouts & retries for SAP
Short, sane timeouts and a retry policy (e.g., Polly) will keep UI responsive.

ABP Auditing
If auditing large bulk ops, consider disabling per-entity auditing during the batch UoW or switch to minimal logs.



---

If you want, I can adapt this to async + cancellation tokens, or show a version that uses EFCore.BulkExtensions to simplify the bulk update path on 3.1.

